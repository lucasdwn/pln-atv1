

# Chatbot RAG - Grade Curricular DSM

Sistema de chatbot inteligente com RAG (Retrieval-Augmented Generation) para responder perguntas sobre a grade curricular do curso de Desenvolvimento de Software Multiplataforma (DSM).

## üìã √çndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Modelo de Linguagem (LLM)](#modelo-de-linguagem-llm)
- [Implementa√ß√£o do RAG](#implementa√ß√£o-do-rag)
- [Limita√ß√µes](#limita√ß√µes)
- [Como Rodar o Projeto](#como-rodar-o-projeto)
- [Como Utilizar](#como-utilizar)
- [Exemplo de Di√°logo](#exemplo-de-di√°logo)
- [Evid√™ncias](#evid√™ncias)

---

## üéØ Sobre o Projeto

Este projeto implementa um chatbot baseado em RAG (Retrieval-Augmented Generation) que utiliza:
- **LLM local**: Google Flan-T5 Large para gera√ß√£o de respostas
- **Embeddings**: sentence-transformers para busca sem√¢ntica
- **Banco vetorial**: FAISS para indexa√ß√£o e recupera√ß√£o eficiente
- **API REST**: FastAPI para interface de comunica√ß√£o

O sistema carrega automaticamente a base de conhecimento sobre a grade DSM e responde perguntas de forma contextualizada.

---

## ü§ñ Modelo de Linguagem (LLM)

### Modelo Escolhido: **Google Flan-T5 Large**

**Por que Flan-T5?**

1. **Gratuito e Open Source**: Totalmente gratuito, sem custos de API
2. **Execu√ß√£o Local**: Roda localmente, garantindo privacidade dos dados
3. **Otimizado para Instru√ß√µes**: Treinado especificamente para seguir instru√ß√µes (instruction-tuned)
4. **Tamanho Balanceado**: 780M par√¢metros - bom equil√≠brio entre qualidade e performance
5. **Multil√≠ngue**: Suporta portugu√™s, ideal para conte√∫do em PT-BR
6. **Baixa Lat√™ncia**: Respostas r√°pidas mesmo em hardware comum

**Especifica√ß√µes T√©cnicas:**
- **Arquitetura**: Transformer encoder-decoder (T5)
- **Par√¢metros**: 780 milh√µes
- **Contexto**: At√© 512 tokens de entrada
- **Framework**: Hugging Face Transformers + PyTorch

---

## üîç Implementa√ß√£o do RAG

O sistema RAG (Retrieval-Augmented Generation) foi implementado em 3 etapas:

### 1. **Indexa√ß√£o (Pr√©-ingest Autom√°tico)**

Na inicializa√ß√£o, o sistema:
- Carrega o arquivo `dsm_data.txt` com a grade curricular
- Divide o conte√∫do em chunks inteligentes:
  - Se√ß√µes por semestre (1¬∫, 2¬∫, 3¬∫)
  - Disciplinas individuais com descri√ß√µes
- Gera embeddings usando `sentence-transformers/all-MiniLM-L6-v2`
- Indexa no FAISS (IndexFlatIP com inner product)

```python
# Exemplo simplificado
vec = embedder.encode([chunk], normalize_embeddings=True)
index.add(vec)
documents.append(chunk)
```

### 2. **Recupera√ß√£o (Retrieval)**

Quando uma pergunta chega:
- Converte a pergunta em embedding vetorial
- Busca no FAISS o documento mais similar (k=1)
- Recupera o contexto relevante da base de conhecimento

```python
q_vec = embedder.encode([question], normalize_embeddings=True)
D, I = index.search(q_vec, 1)  # Top-1 similar
context = documents[I[0][0]]
```

### 3. **Gera√ß√£o (Augmented Generation)**

- Monta um prompt estruturado com contexto + pergunta
- Envia para o Flan-T5 Large
- Gera resposta contextualizada baseada no conhecimento recuperado

```python
prompt = f"""Use o contexto abaixo para responder √† pergunta de forma clara e direta.

Contexto:
{context}

Pergunta:
{question}

Resposta:"""
```

**Par√¢metros de Gera√ß√£o:**
- `max_new_tokens=200`: Respostas concisas
- `temperature=0.7`: Equil√≠brio entre criatividade e precis√£o
- `top_p=0.9`: Nucleus sampling para qualidade

---

## ‚ö†Ô∏è Limita√ß√µes

### 1. **Capacidade do Modelo**
- Flan-T5 Large tem 780M par√¢metros (menor que GPT-3.5/GPT-4)
- Pode gerar respostas menos sofisticadas em perguntas complexas
- Limitado a 512 tokens de contexto

### 2. **Busca Vetorial**
- Recupera apenas 1 documento (k=1) por consulta
- Pode perder informa√ß√µes relevantes em outros chunks
- N√£o faz fus√£o de m√∫ltiplas fontes

### 3. **Base de Conhecimento**
- Limitada √†s informa√ß√µes no `dsm_data.txt`
- N√£o tem conhecimento al√©m da grade curricular fornecida
- N√£o se atualiza automaticamente

### 4. **Performance**
- Primeira execu√ß√£o baixa modelos (~3GB) - pode demorar
- Requer pelo menos 4GB de RAM dispon√≠vel
- CPU-only pode ser lento (GPU recomendada)

### 5. **Idioma**
- Apesar de multil√≠ngue, pode misturar ingl√™s/portugu√™s ocasionalmente
- Melhor desempenho em ingl√™s que portugu√™s

### 6. **Escalabilidade**
- FAISS em mem√≥ria - perde dados ao reiniciar
- N√£o persiste o √≠ndice vetorial
- N√£o suporta m√∫ltiplos usu√°rios concorrentes eficientemente

---

## üöÄ Como Rodar o Projeto

### 1. Criar Ambiente Virtual

```powershell
# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente
.venv\Scripts\activate    # Windows (PowerShell)
```

### 2. Instalar Depend√™ncias

```powershell
pip install -r requirements.txt
```

**Nota**: A primeira execu√ß√£o baixar√° os modelos (~3GB). Aguarde a conclus√£o.

### 3. Rodar Aplica√ß√£o

```powershell
uvicorn app:app --reload --port 8000
```

Voc√™ ver√° as mensagens:
```
üîÑ Carregando modelo...
üìö Carregando dados do arquivo dsm_data.txt...
‚úÖ Pr√©-ingest conclu√≠do! X documentos indexados.
```

A API estar√° dispon√≠vel em: `http://localhost:8000`

---

## üí° Como Utilizar

### Fazer Perguntas (Endpoint /ask)

O sistema j√° vem com a base DSM pr√©-carregada. Basta fazer perguntas!

**Exemplo de requisi√ß√£o:**

```http
POST http://localhost:8000/ask
Content-Type: application/json

{
    "question": "Quais s√£o as disciplinas do 1¬∫ semestre?"
}
```

**Mais exemplos est√£o dispon√≠veis no arquivo `request.http`**

### Adicionar Novos Dados (Endpoint /ingest) - Opcional

Caso queira adicionar informa√ß√µes adicionais:

```http
POST http://localhost:8000/ingest
Content-Type: application/json

{
    "text": "Texto adicional sobre o curso DSM..."
}
```

### Verificar Status (Endpoint /health)

```http
GET http://localhost:8000/health
```

---

## üí¨ Exemplo de Di√°logo (5 Intera√ß√µes)

### **Intera√ß√£o 1**
**Usu√°rio**: "Quais s√£o as disciplinas do 1¬∫ semestre do curso DSM?"

**Chatbot**: "O 1¬∫ semestre do curso DSM possui 6 disciplinas: IAL010 ‚Äì Algoritmos e L√≥gica de Programa√ß√£o, ISO011 ‚Äì Sistemas Operacionais e Redes de Computadores, IBD014 ‚Äì Modelagem de Banco de Dados, ISW028 ‚Äì Desenvolvimento Web I, IES011 ‚Äì Engenharia de Software I, e ISW031 ‚Äì Design Digital."

---

### **Intera√ß√£o 2**
**Usu√°rio**: "O que √© ensinado em Algoritmos e L√≥gica de Programa√ß√£o?"

**Chatbot**: "IAL010 ‚Äì Algoritmos e L√≥gica de Programa√ß√£o √© a disciplina fundamental que ensina os conceitos b√°sicos de algoritmos, estruturas de controle, vari√°veis e l√≥gica de programa√ß√£o. √â a base para o desenvolvimento de software no curso."

---

### **Intera√ß√£o 3**
**Usu√°rio**: "Quais disciplinas de banco de dados tem no curso?"

**Chatbot**: "O curso DSM possui tr√™s disciplinas de banco de dados: IBD014 ‚Äì Modelagem de Banco de Dados no 1¬∫ semestre, que ensina diagrama entidade-relacionamento e normaliza√ß√£o; IBD015 ‚Äì Banco de Dados Relacional no 2¬∫ semestre, focado em SQL e PostgreSQL; e IBD016 ‚Äì Banco de Dados N√£o Relacional no 3¬∫ semestre, que estuda MongoDB e bancos NoSQL."

---

### **Intera√ß√£o 4**
**Usu√°rio**: "O que √© estudado em Desenvolvimento Web II?"

**Chatbot**: "ISW029 ‚Äì Desenvolvimento Web II √© uma disciplina do 2¬∫ semestre que avan√ßa no desenvolvimento web com frameworks JavaScript modernos como React, Vue.js ou Angular, al√©m de trabalhar com APIs RESTful e arquitetura frontend."

---

### **Intera√ß√£o 5**
**Usu√°rio**: "O que √© MongoDB e em qual semestre √© estudado?"

**Chatbot**: "MongoDB √© um banco de dados NoSQL estudado na disciplina IBD016 ‚Äì Banco de Dados N√£o Relacional, oferecida no 3¬∫ semestre do curso DSM. A disciplina aborda modelagem de dados n√£o relacionais, escalabilidade e performance em bancos NoSQL como MongoDB, Redis e Cassandra."

---

## üì∏ Evid√™ncias

### Pr√©-ingest Autom√°tico
O sistema carrega automaticamente a base de conhecimento DSM na inicializa√ß√£o.

![Ingest](./prints/ingest.png)

### Pergunta 1 - Disciplinas do 1¬∫ Semestre
![Question](./prints/question.png)

### Pergunta 2 - Algoritmos e L√≥gica de Programa√ß√£o
![Ask 2](./prints/ask2.png)

### Pergunta 3 - Disciplinas de Banco de Dados
![Ask 3](./prints/ask3.png)

### Pergunta 4 - Desenvolvimento Web II
![Ask 4](./prints/ask4.png)

### Pergunta 5 - MongoDB
![Ask 5](./prints/ask5.png)

---

## üì¶ Tecnologias Utilizadas

- **Python 3.8+**
- **FastAPI**: Framework web ass√≠ncrono
- **Transformers (Hugging Face)**: LLM Flan-T5
- **Sentence-Transformers**: Embeddings sem√¢nticos
- **FAISS**: Busca vetorial eficiente
- **PyTorch**: Backend de deep learning
- **Uvicorn**: Servidor ASGI

---

## üë®‚Äçüíª Autor

Projeto desenvolvido como atividade da disciplina de Processamento de Linguagem Natural (PLN).

**Reposit√≥rio**: [lucasdwn/pln-atv1](https://github.com/lucasdwn/pln-atv1)